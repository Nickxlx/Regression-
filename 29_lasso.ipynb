{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9c6d8f-ce73-4ec6-913b-8216b762d7e9",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "Answer--> \n",
    "Lasso Regression, also known as L1 Regularization, is a regression technique that combines ordinary least squares regression with a penalty term to shrink the coefficients of less important predictors towards zero. It is used for variable selection and regularization in machine learning .\n",
    "\n",
    "Lasso Regression differs from other regression techniques in that it introduces a penalty term based on the absolute values of the coefficients. This penalty term encourages sparsity in the model by shrinking less important coefficients to exactly zero, effectively performing variable selection. In contrast, other regression techniques such as Ridge Regression use a penalty term based on the squared values of the coefficients, which results in smaller but non-zero coefficients for all predictors. Therefore, Lasso Regression is more suitable for feature selection and can create simpler and more interpretable models by automatically eliminating irrelevant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc253a53-6837-4754-b97b-ecb3c5c72ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de5460-3b77-4ee3-b1d3-881256093a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca287a0d-3ac5-4aed-9ab1-9218ae6fb3b6",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "Answer--> Lasso regression techniques in which it introduces a penalty term based on the absolute values of the coefficients. This penalty term encourages sparsity in the model by shrinking less important coefficients to exactly zero, effectively performing variable selection. Therefore, Lasso Regression is more suitable for feature selection and can create simpler and more interpretable models by automatically eliminating irrelevant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e611a-7cd8-4b5f-80f4-e9aa31f2e425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc8728-3cab-4525-a1bd-1ba0d8bff0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca067fd-925c-4853-8690-ad001be4d76c",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "Answer-->  The coefficients represent the estimated effect of each predictor variable on the target variable, taking into account the regularization applied by the Lasso penalty.\n",
    "\n",
    "In Lasso Regression, some coefficients may be exactly zero, indicating that the corresponding predictors have been eliminated from the model. The non-zero coefficients indicate the importance and direction of the relationship between the predictor and the target variable. A positive coefficient suggests a positive relationship, meaning that as the predictor increases, the target variable tends to increase as well. Conversely, a negative coefficient suggests a negative relationship, indicating that as the predictor increases, the target variable tends to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c19da5-064f-4d97-b097-4dfe0291ebd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3a5f9-674d-4c97-9c09-b0269365dd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b29ff371-01d5-4898-9f76-ee47bb83e6ff",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "Answer--> In Lasso Regression, the main tuning parameter is the regularization parameter, often denoted as \"lamda\" or \"alpha\" (Î±). The regularization parameter controls the amount of penalty applied to the coefficient estimates. By adjusting the value of alpha, you can control the level of regularization and, consequently, the sparsity of the model.\n",
    "\n",
    "A higher value of alpha increases the penalty, resulting in more coefficients being shrunk to zero. This encourages sparsity and can lead to a simpler model with fewer predictors. On the other hand, a lower value of alpha reduces the penalty, allowing more coefficients to remain non-zero. This can result in a more complex model with more predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0bf43-4b7e-47d0-af92-8ab3e17d44e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447ec6a-c327-4010-b49e-d2fc71b3c5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9091d806-69fb-417f-ba1d-a272a832f29e",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Answer--> Lasso Regression, by itself, is a linear regression technique and is primarily used for linear regression problems. It is designed to estimate linear relationships between predictors and the target variable. However, Lasso Regression can be extended to handle non-linear regression problems by incorporating non-linear transformations of the predictors.\n",
    "\n",
    "To apply Lasso Regression to non-linear regression problems, you can introduce non-linear transformations of the predictors as additional features in the model. For example, you can include polynomial terms, interaction terms, or other non-linear transformations of the predictors. By adding these transformed features to the model, you allow the Lasso Regression to capture non-linear relationships between the predictors and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36648ca7-042e-4bf4-a60d-b8d2870199b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113918ee-30ac-41d4-8569-d3398c22fe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f573abfb-948f-4fb2-aef3-6c3074e9d25d",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "Answer--> Lasso Regression differs from Ridge regression techniques in that it introduces a penalty term based on the absolute values of the coefficients. This penalty term encourages sparsity in the model by shrinking less important coefficients to exactly zero, effectively performing variable selection. In contrast, Ridge Regression use a penalty term based on the squared values of the coefficients, which results in smaller but non-zero coefficients for all predictors. Therefore, Lasso Regression is more suitable for feature selection and can create simpler and more interpretable models by automatically eliminating irrelevant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868bd37a-e56c-4336-87e5-9c21b3823bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76188417-d653-4118-bb19-74fb1f94f7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06c8d0b9-6cf8-43e3-9e76-3df72c0f0ebd",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?  \n",
    "\n",
    "Answer--> ChatGPT\n",
    "Yes, Lasso Regression has the ability to handle multicollinearity in the input features to some extent.Lasso Regression addresses multicollinearity by introducing a regularization term that encourages sparsity in the coefficient estimates. This means that Lasso Regression tends to shrink some of the coefficients towards zero, effectively performing feature selection by identifying and removing less important predictors.\n",
    "\n",
    "In the presence of multicollinearity, Lasso Regression can select one of the correlated predictors and assign it a non-zero coefficient while setting the coefficients of the other correlated predictors to zero. This helps in identifying the most important predictors among the correlated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a46be4-062f-4951-8aa6-af3823042a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bcd14-639c-4312-9a9e-73f0ba4802b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d6e9ba-26d3-4757-ac24-7e86947dc960",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "Answer--> \n",
    "In Lasso Regression, the regularization parameter (lambda) controls the amount of regularization applied to the model. It determines the trade-off between the magnitude of the coefficients and the error term in the model.\n",
    "\n",
    "To choose the optimal value of lambda in Lasso Regression, you can use techniques such as:\n",
    "    \n",
    "    1  cross-validation \n",
    "    2  grid search\n",
    "    \n",
    "Both cross-validation and grid search help in selecting the lambda value that provides the best trade-off between model complexity and model performance. It is important to note that the optimal lambda value may vary depending on the specific dataset and the evaluation metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab851af-ce76-4dc2-a117-bd1523eda529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82d21c-2671-43c3-bf19-e8b771d4dbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
